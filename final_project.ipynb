{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython import get_ipython\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Data preprocessing and cleaning\n",
    "data_path = r'winequalityN.csv'\n",
    "wine = pd.read_csv(data_path)\n",
    "\n",
    "# explore whole data set\n",
    "print(wine.info())\n",
    "print(wine.describe())\n",
    "\n",
    "# splitting  red/white datasets\n",
    "white = wine[wine['type'] == 'white']\n",
    "red = wine[wine['type'] == 'red']\n",
    "\n",
    "# removing 'type' columns\n",
    "white = white.drop(columns = ['type'])\n",
    "red = red.drop(columns = ['type'])\n",
    "\n",
    "# dropping records w/ missing values\n",
    "white = white.dropna()\n",
    "red = red.dropna()\n",
    "\n",
    "bins = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "\n",
    "# white wine\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(white['quality'], bins=bins, align='left')\n",
    "ax.set_title('Histogram of White Wine Quality')\n",
    "ax.set_xlabel('Quality')\n",
    "ax.set_ylabel('Count')\n",
    "sns.set(style=\"whitegrid\")\n",
    "rects = ax.patches\n",
    "for rect in rects:\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 0.5, '{:.0f}'.format(height), ha='center', va = 'bottom')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# red wine\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(red['quality'], bins=bins, align='left')\n",
    "ax.set_title('Histogram of Red Wine Quality')\n",
    "ax.set_xlabel('Quality')\n",
    "ax.set_ylabel('Count')\n",
    "sns.set(style=\"whitegrid\")\n",
    "rects = ax.patches\n",
    "for rect in rects:\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 0.5, '{:.0f}'.format(height), ha='center', va = 'bottom')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "              \n",
    "# dropping 'outliers', i.e., records w/ 'quality' values of 3 or 9\n",
    "white = white[(white.quality != 3) & (white.quality != 9)]\n",
    "red = red[(red.quality != 3) & (red.quality != 9)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exploratory Analysis of Each Wine\n",
    "# Data summary (mean, median, standard deviation, etc.)\n",
    "# White wine\n",
    "print(\"\\nWhite Wine\\n\")\n",
    "print(white.describe())\n",
    "print(white.info())\n",
    "\n",
    "# Red wine\n",
    "print(\"\\n\\nRed Wine\\n\")\n",
    "print(red.describe())\n",
    "print(red.info())\n",
    "\n",
    "\n",
    "## Data visualizations\n",
    "\n",
    "labels = [4, 5, 6, 7, 8]\n",
    "# Histograms\n",
    "# white wine\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(white['quality'], bins=labels, align='left')\n",
    "ax.set_title('Histogram of White Wine Quality')\n",
    "ax.set_xlabel('Quality')\n",
    "ax.set_ylabel('Count')\n",
    "sns.set(style=\"whitegrid\")\n",
    "rects = ax.patches\n",
    "for rect in rects:\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 0.5, '{:.0f}'.format(height), ha='center', va = 'bottom')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# red wine\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(red['quality'], bins=labels, align='left')\n",
    "ax.set_title('Histogram of Red Wine Quality')\n",
    "ax.set_xlabel('Quality')\n",
    "ax.set_ylabel('Count')\n",
    "sns.set(style=\"whitegrid\")\n",
    "rects = ax.patches\n",
    "for rect in rects:\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 0.5, '{:.0f}'.format(height), ha='center', va = 'bottom')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "# appears that quality of both red and white wine follows roughly a normal distribution\n",
    "\n",
    "# Correlation maps\n",
    "# white wine\n",
    "plt.figure(figsize=(10,6))\n",
    "corr_white = sns.heatmap(white.corr(), annot=True, cmap='Blues')\n",
    "corr_white.set_title('Correlation Map - White Wine')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "# red wine\n",
    "plt.figure(figsize=(10,6))\n",
    "corr_red = sns.heatmap(red.corr(), annot=True, cmap='Blues')\n",
    "corr_red.set_title('Correlation Map - Red Wine')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "# alcohol content has highest correlation with quality for both red and white wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train/Test Split and Data Standardizations\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "def FeatureSelection(k, df, x_train, y_train, x_test, y_test):\n",
    "    s = SelectKBest(k=k).fit(x_train, y_train)\n",
    "    mask = s.get_support(True)\n",
    "    selected_features = df.columns[mask].tolist()\n",
    "    train_selected = SelectKBest(k=k).fit_transform(x_train, y_train)\n",
    "    test_selected = SelectKBest(k=k).fit_transform(x_test, y_test)\n",
    "    return train_selected, test_selected, selected_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Paper did a 2/3 1/3 split\n",
    "# It eventually won't matter when we do k-fold cross validation\n",
    "# but it can easily be adjusted for preliminary models with test_size=0.33\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "test_size = 0.2\n",
    "\n",
    "# Red wine\n",
    "red_x = red.drop(['quality'], axis=1)\n",
    "red_y = red['quality']\n",
    "red_train_x, red_test_x, red_train_y, red_test_y = train_test_split(red_x, red_y, test_size=test_size, random_state=42, shuffle=True, stratify=red_y)\n",
    "red_train_y = red_train_y.to_numpy()\n",
    "red_test_y = red_test_y.to_numpy()\n",
    "\n",
    "# White wine\n",
    "white_x = white.drop(['quality'], axis=1)\n",
    "white_y = white['quality']\n",
    "white_train_x, white_test_x, white_train_y, white_test_y = train_test_split(white_x, white_y, test_size=test_size, random_state=42, shuffle=True, stratify=white_y)\n",
    "white_train_y = white_train_y.to_numpy()\n",
    "white_test_y = white_test_y.to_numpy()\n",
    "              \n",
    "# creating index of features\n",
    "features = white_train_x.columns\n",
    "\n",
    "# standardizing feature values\n",
    "scaler = StandardScaler()\n",
    "white_train_x = scaler.fit_transform(white_train_x)\n",
    "white_test_x = scaler.fit_transform(white_test_x)\n",
    "red_train_x = scaler.fit_transform(red_train_x)\n",
    "red_test_x = scaler.fit_transform(red_test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting with feature selection\n",
    "## Defining functions\n",
    "def diff(l1, l2):\n",
    "    return (list(list(set(l1)-set(l2))+ list(set(l2)-set(l1))))\n",
    "\n",
    "l_red = []\n",
    "l_white = []\n",
    "sel_features_inorder_white = []\n",
    "sel_features_inorder_red = []\n",
    "for i in range(1, 12):\n",
    "    white_train, white_test, white_selected_features = FeatureSelection(i, white_x, white_train_x, white_train_y, white_test_x, white_test_y)\n",
    "    l_white.append(white_selected_features)\n",
    "    red_train, red_test, red_selected_features = FeatureSelection(i, red_x, red_train_x, red_train_y, red_test_x, red_test_y)\n",
    "    l_red.append(red_selected_features)\n",
    "    if i == 1:\n",
    "        sel_features_inorder_white.append(l_white[0])\n",
    "        sel_features_inorder_red.append(l_red[0])\n",
    "    else:\n",
    "        sel_features_inorder_white.append(diff(l_white[i-1], l_white[i-2]))\n",
    "        sel_features_inorder_red.append(diff(l_red[i-1], l_red[i-2]))\n",
    "        \n",
    "print(f'White selected features, in order: {sel_features_inorder_white}')\n",
    "print(f'Red selected features, in order: {sel_features_inorder_red}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perplexity = 50 for white test data perplexity = 20 for red test data\n",
    "#I might have to play around a little bit more\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def two_dimensional_representation(x_data,y_data,title=\"t-SNE wine\",perplexity = 50):\n",
    "    tsne = TSNE(verbose=1, perplexity=perplexity, random_state = 42)\n",
    "    X_embedded_data = tsne.fit_transform(x_data)\n",
    "\n",
    "    # sns settings\n",
    "    sns.set(rc={'figure.figsize':(10,10)})\n",
    "\n",
    "    # colors\n",
    "    palette = sns.color_palette(\"bright\", len(set(y_data)))\n",
    "\n",
    "    # plot\n",
    "    sns.scatterplot(X_embedded_data[:,0], X_embedded_data[:,1], hue = y_data, palette=palette)\n",
    "\n",
    "    plt.title(title)\n",
    "    # plt.savefig(\"plots/t-sne_wine.png\")\n",
    "    plt.show()\n",
    "\n",
    "two_dimensional_representation(red_test_x,red_test_y,\"Red actual\",20)\n",
    "two_dimensional_representation(white_test_x,white_test_y,\"White actual\",50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper Functions/Variables and Imports\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def confusion(test, pred, labels, title):\n",
    "    d = confusion_matrix(test, pred, labels = labels)\n",
    "    df_cm = pd.DataFrame(d, columns = labels, index = labels)\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    df_cm.index.name = 'Actual'\n",
    "    cm = sns.heatmap(df_cm, cmap = 'Blues', linewidths = 0.1, annot=True, fmt = 'd')\n",
    "    cm.tick_params(left = False, bottom = False)\n",
    "    cm.set_title(title)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "def plot_metrics(df, metric, color):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    sns.despine(left=True)\n",
    "    d = df[(df.Color==color)]\n",
    "    print(d)\n",
    "    plot = sns.barplot(x=d['Classifier'], y=d[metric])\n",
    "    plt.title(f'Classification {metric} - {color} Wine dataset')\n",
    "    if metric == 'SSE':\n",
    "        fmt = '0.0f'\n",
    "    else:\n",
    "        fmt = '0.5f'\n",
    "    for p in plot.patches:\n",
    "        plot.annotate(format(p.get_height(), fmt),\n",
    "                      (p.get_x() + p.get_width()/2, p.get_height()), \n",
    "                       ha = 'center', va = 'center',\n",
    "                       xytext = (0,-20), \n",
    "                       textcoords = 'offset points', color = 'white')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "# defining SSE\n",
    "def SSE(actual, pred):\n",
    "    s = 0\n",
    "    for i in range(len(actual)):\n",
    "        s += abs(actual[i]-pred[i])**2\n",
    "    return s\n",
    "\n",
    "#Prints aout SSE and Accuracy Data and prints out graph\n",
    "#Example\n",
    "#svm_function(white_train_x, white_train_y, white_test_x, white_test_y)\n",
    "#data_analyze(\"White\", white_svm, \"SVM\")\n",
    "score_df_col = [\"Classifier\", \"Color\", \"Accuracy\", \"SSE\"]\n",
    "score_df = pd.DataFrame(columns=score_df_col)\n",
    "\n",
    "def data_analyze(test_y, y_pred, wine_color, classifier_name):\n",
    "    wine_color = wine_color.title()\n",
    "    labels = [4,5,6,7,8]\n",
    "\n",
    "    acc = accuracy_score(test_y, y_pred)\n",
    "    SSE_data = SSE(test_y, y_pred)\n",
    "    score_df.loc[len(score_df.index)] = [classifier_name, wine_color, acc, SSE_data]\n",
    "    \n",
    "    print (f\"Accuracy for {classifier_name} on {wine_color} dataset is {acc}\")\n",
    "    print (f\"SSE for {classifier_name} on {wine_color} dataset is {SSE_data}\")\n",
    "    title = f\"{classifier_name} - {wine_color} Wine\"\n",
    "    confusion(test_y, y_pred, labels, title)\n",
    "\n",
    "\n",
    "def ROC_AUC(y_pred, y_true, pos_group=None):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true=y_true, y_score=y_pred, pos_label=pos_group)\n",
    "    auc_result = metrics.auc(fpr, tpr)\n",
    "    return fpr, tpr, auc_result\n",
    "\n",
    "def plotROCAUC(df, df2, classes, micro_fpr, micro_tpr, micro_roc_auc):\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate( [df2['fpr'][i] for i in classes] ))\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in classes:\n",
    "        mean_tpr += np.interp(all_fpr, df2['fpr'][i], df2['tpr'][i])\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= len(classes)\n",
    "    macro_fpr = all_fpr\n",
    "    macro_tpr = mean_tpr\n",
    "    macro_roc_auc = metrics.auc(macro_fpr, macro_tpr)\n",
    "    # Plot ROC AUC curves\n",
    "    lw = 2\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(micro_fpr, micro_tpr, label='micro-average ROC curve (area = {0:0.2f})'.format(micro_roc_auc),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "    plt.plot(macro_fpr, macro_tpr, label='macro-average ROC curve (area = {0:0.2f})'.format(macro_roc_auc),\n",
    "         color='crimson', linestyle=':', linewidth=4)\n",
    "    colors = ['aqua', 'darkorange', 'cyan', 'lightcoral', 'olive', 'fuchsia', 'indigo']\n",
    "    for i, color in zip(classes, colors[:len(classes)]):\n",
    "        plt.plot(df2['fpr'][i], df2['tpr'][i], color=color, lw=lw,\n",
    "                label='ROC curve of class {0} (area = {1:0.2f})'.format(i, df['roc auc'][i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic to multi-class')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def PR_AUC(y_pred, y_true, pos_group=None):\n",
    "    avg_precision = metrics.average_precision_score(y_true=y_true, y_score=y_pred, pos_label=pos_group)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_true=y_true, probas_pred=y_pred, pos_label=pos_group)\n",
    "    return precision, recall, avg_precision\n",
    "\n",
    "def plotPRAUC(df, df2, classes, y_test, y_score, micro_precision, micro_recall, micro_avg_precision):\n",
    "    # honeslty I don't know if this is portable or correct...meh\n",
    "    # First aggregate all precision\n",
    "    all_precision = np.unique(np.concatenate( [df2['precision'][i] for i in classes] ))\n",
    "    # Then interpolate all pr curves at this points\n",
    "    mean_recall = np.zeros_like(all_precision)\n",
    "    for i in classes:\n",
    "        mean_recall += np.interp(all_precision, df2['precision'][i], df2['recall'][i])\n",
    "    # Finally average it and compute AUC\n",
    "    mean_recall /= len(classes)\n",
    "    macro_precision = all_precision\n",
    "    macro_recall = mean_recall    \n",
    "    macro_avg_precision = metrics.average_precision_score(y_true=y_test, y_score=y_score, pos_label=1)\n",
    "    # macro_avg_precision_auc = metrics.auc(macro_precision, macro_recall)\n",
    "    # print(macro_avg_precision_auc, macro_avg_precision)\n",
    "    # average precision, also know as precision-recall area under the curve\n",
    "    # Plot PR AUC curves\n",
    "    lw = 2\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(micro_precision, micro_recall, label='micro-average PR curve (area = {0:0.2f})'.format(micro_avg_precision),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "    plt.plot(macro_precision, macro_recall, label='macro-average PR curve (area = {0:0.2f})'.format(macro_avg_precision),\n",
    "         color='crimson', linestyle=':', linewidth=4)\n",
    "    colors = ['aqua', 'darkorange', 'cyan', 'lightcoral', 'olive', 'fuchsia', 'indigo']\n",
    "    for i, color in zip(classes, colors[:len(classes)]):\n",
    "        plt.plot(df2['precision'][i], df2['recall'][i], color=color, lw=lw,\n",
    "                label='PR curve of class {0} (area = {1:0.2f})'.format(i, df['pr avg prec'][i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.title('Precision-Recall to multi-class')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "def oneVsRestAnalysis(model, X_train, y_train, X_test, y_test, classes):\n",
    "    # https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "\n",
    "    # Binarize the output\n",
    "    y_train = label_binarize(y_train, classes=classes)\n",
    "    y_test = label_binarize(y_test, classes=classes)\n",
    "    # create classifier for multi-label classification\n",
    "    clf = OneVsRestClassifier(model)\n",
    "    y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "    # Compute performance metrics\n",
    "    curve_dict = { 'quality': [], 'fpr': [], 'tpr': [], 'precision': [], 'recall': [] }\n",
    "    df_dict = { 'quality': [], 'roc auc': [], 'pr avg prec': [] } \n",
    "    for i,x in enumerate(classes):\n",
    "        df_dict['quality'].append(x)\n",
    "        curve_dict['quality'].append(x)\n",
    "        # curves can't handle mutli-label, so only give column that correpsonds to binarized label with [:, i]\n",
    "        fpr, tpr, roc_auc = ROC_AUC(y_true=y_test[:, i], y_pred=y_score[:, i], pos_group=1)\n",
    "        curve_dict['fpr'].append(fpr)\n",
    "        curve_dict['tpr'].append(tpr)\n",
    "        df_dict['roc auc'].append(roc_auc)\n",
    "\n",
    "        prec, recall, pr_avg_prec = PR_AUC(y_true=y_test[:, i], y_pred=y_score[:, i], pos_group=1)\n",
    "        curve_dict['precision'].append(prec)\n",
    "        curve_dict['recall'].append(recall)\n",
    "        df_dict['pr avg prec'].append(pr_avg_prec)\n",
    "\n",
    "    # Compute micro-averages \n",
    "    micro_fpr, micro_tpr, micro_roc_auc = ROC_AUC(y_true=y_test.ravel(), y_pred=y_score.ravel(), pos_group=1)\n",
    "    micro_precision, micro_recall, micro_avg_precision = PR_AUC(y_true=y_test.ravel(), y_pred=y_score.ravel(), pos_group=1)\n",
    "\n",
    "    # Analyze roc_auc and pr_auc for the classes\n",
    "    df = pd.DataFrame.from_dict(df_dict)\n",
    "    df.set_index('quality', inplace=True)\n",
    "\n",
    "    df2 = pd.DataFrame.from_dict(curve_dict)\n",
    "    df2.set_index('quality', inplace=True)\n",
    "\n",
    "    plotROCAUC(df, df2, classes, micro_fpr, micro_tpr, micro_roc_auc)\n",
    "\n",
    "    plotPRAUC(df, df2, classes, y_test, y_score, micro_precision, micro_recall, micro_avg_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trivial classifier \n",
    "# predicts the mode (6 for white records, 5 for red) for all records\n",
    "# this will serve as baseline for performance\n",
    "from scipy import stats\n",
    "\n",
    "# TODO: X data sets for trian and test are unused\n",
    "def do_trivial(train_x, train_y, test_x, test_y, color):\n",
    "    pred = np.full(test_y.shape, stats.mode(train_y)[0])\n",
    "    data_analyze(test_y, pred, color, 'Trivial')\n",
    "    return pred\n",
    "\n",
    "do_trivial(white_train_x, white_train_y, white_test_x, white_test_y, 'White')\n",
    "do_trivial(red_train_x, red_train_y, red_test_x, red_test_y, 'Red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate Author's SVM\n",
    "from sklearn.svm import SVR\n",
    "def Authors_SVM(x_train, y_train, x_test, y_test, color=None):\n",
    "    # using gamma values that the authors found were the best\n",
    "    white_gamma = 2**1.55  # 2.928\n",
    "    red_gamma = 2**0.19  # 1.14\n",
    "    gamma = np.logspace(-3, 6, 20, 2)\n",
    "    grid_search = {'C':range(1,20), 'gamma':gamma}\n",
    "    best_w = {'C': [2], 'gamma': [0.6951927961775606]}\n",
    "    best_r = {'C': [1], 'gamma': [0.07847599703514611]}\n",
    "    author_params = {'C':[3], 'gamma':[white_gamma, red_gamma]}\n",
    "    svm_clf = SVR(kernel='rbf')\n",
    "    param=None\n",
    "    if color == 'white':\n",
    "        param = best_w\n",
    "    elif color == 'red':\n",
    "        param = best_r\n",
    "    elif color == 'authors-red' or color == 'authors-white':\n",
    "        param = author_params\n",
    "    else:  # no color given then seraches for best scores\n",
    "        param = grid_search\n",
    "\n",
    "    clf = GridSearchCV(svm_clf, param, n_jobs=1, verbose=True, cv=5)\n",
    "\n",
    "    #new_x_train, new_x_test = FeatureSelection(11, x_train, y_train, x_test, y_test)\n",
    "    new_x_train = x_train\n",
    "    new_x_test = x_test\n",
    "    clf.fit(new_x_train, y_train)\n",
    "    y_pred = clf.predict(new_x_test)\n",
    "    y_pred = np.rint(y_pred)  # round predictions to nearest integer for classification\n",
    "\n",
    "    if color == 'white' or color == 'red' or color == 'authors-red' or color == 'authors-white':\n",
    "        data_analyze(y_test, y_pred, color, \"Auth-SVM\")\n",
    "\n",
    "    if color==None:\n",
    "        print('best parameters: {}', clf.best_params_)\n",
    "        print('best score: {}', clf.best_score_)\n",
    "        print(\"MAE: {}\", mean_absolute_error(y_test, y_pred)) \n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(precision_score(y_test, y_pred, average=None, zero_division=0))\n",
    "\n",
    "Authors_SVM(white_train_x, white_train_y, white_test_x, white_test_y, 'white')\n",
    "Authors_SVM(red_train_x, red_train_y, red_test_x, red_test_y, 'red')\n",
    "Authors_SVM(white_train_x, white_train_y, white_test_x, white_test_y, 'authors-white')\n",
    "Authors_SVM(red_train_x, red_train_y, red_test_x, red_test_y, 'authors-red')\n",
    "Authors_SVM(white_train_x, white_train_y, white_test_x, white_test_y)\n",
    "Authors_SVM(red_train_x, red_train_y, red_test_x, red_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kmeans clustering\n",
    "from sklearn.cluster import KMeans\n",
    "def K_means(x_train, y_train, x_test, y_test, title = \"Wine\"):\n",
    "    distortions = []\n",
    "    for k in range(1,11):\n",
    "        kmeans = KMeans(n_clusters=k, verbose=False, random_state=42)\n",
    "        kmeans.fit(x_train, y_train)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "    plt.plot(range(1, 11), distortions, marker='o')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    # print confusion matrix\n",
    "    #conf = confusion_matrix(y_test, y_pred)\n",
    "    #print(conf)\n",
    "    \n",
    "    # get precision scores\n",
    "    #prec_w = precision_score(y_test, y_pred, average=None, zero_division=0)\n",
    "    #print(prec_w)\n",
    "\n",
    "K_means(white_train_x, white_train_y, white_test_x, white_test_y,\"white wine\")\n",
    "K_means(red_train_x, red_train_y, red_test_x, red_test_y,\"red wine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radius Nearest Neighbors, the unsupervised version doesn't allow for classification\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "def RNC(x_train, y_train, x_test, y_test, color=None):\n",
    "    grid_search = {\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'radius': np.arange(1.0, 11.0, 0.5),\n",
    "        'n_jobs': [1],\n",
    "        'outlier_label':['most_frequent'],\n",
    "        'algorithm': ['ball_tree', 'kd_tree', 'brute']\n",
    "        }\n",
    "    best_w = {'algorithm': ['ball_tree'], 'n_jobs': [1], 'outlier_label': ['most_frequent'], 'radius': [2.5], 'weights': ['distance']}\n",
    "    best_r = {'algorithm': ['ball_tree'], 'n_jobs': [1], 'outlier_label': ['most_frequent'], 'radius': [2.5], 'weights': ['distance']}\n",
    "    param=None\n",
    "    if color == 'white':\n",
    "        param = best_w\n",
    "    elif color == 'red':\n",
    "        param = best_r\n",
    "    else:\n",
    "        param = grid_search\n",
    "    model = RadiusNeighborsClassifier()\n",
    "    clf = GridSearchCV(model, param, n_jobs=1, verbose=True, cv=3)  # cv=3 so that we have enough classes in each k-fold\n",
    "\n",
    "    new_x_train, new_x_test, selected_features = FeatureSelection(11, red_x, x_train, y_train, x_test, y_test)\n",
    "    # new_x_train = x_train\n",
    "    # new_x_test = x_test\n",
    "    clf.fit(new_x_train, y_train)\n",
    "    y_pred = clf.predict(new_x_test)\n",
    "\n",
    "\n",
    "    y_pred = np.rint(y_pred)  # round predictions to nearest integer for classification\n",
    "\n",
    "    if color == 'white' or color == 'red':\n",
    "        data_analyze(y_test, y_pred, color, \"RNC\")\n",
    "\n",
    "    if color==None:\n",
    "        print('best parameters: {}', clf.best_params_)\n",
    "        print('best score: {}', clf.best_score_)\n",
    "        print(\"MAE: {}\", mean_absolute_error(y_test, y_pred)) \n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(precision_score(y_test, y_pred, average=None, zero_division=0))\n",
    "    \n",
    "RNC(white_train_x, white_train_y, white_test_x, white_test_y, 'white')\n",
    "RNC(red_train_x, red_train_y, red_test_x, red_test_y, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import tree\n",
    "def do_tree(train_x, train_y, test_x, test_y, params, color):\n",
    "    dt = tree.DecisionTreeClassifier(max_depth = params['max_depth'],\n",
    "                                      max_leaf_nodes = params['max_leaf_nodes'],\n",
    "                                      criterion = params['criterion'],\n",
    "                                      random_state = 42)\n",
    "    d = dt.fit(train_x, train_y)\n",
    "    pred = d.predict(test_x)\n",
    "    data_analyze(test_y, pred, color, 'DT')\n",
    "    return pred\n",
    "\n",
    "def optimize_tree(df, x_train, y_train, x_test, y_test, params):\n",
    "    n = []\n",
    "    parameters = []\n",
    "    accuracy = []\n",
    "    sse = []\n",
    "    for i in range(1,12):\n",
    "        n.append(i)\n",
    "        train, test, x = FeatureSelection(i, df, x_train, y_train, x_test, y_test)\n",
    "        dt = tree.DecisionTreeClassifier(random_state = 42)\n",
    "        clf = RandomizedSearchCV(dt, params, n_jobs=1, n_iter=10, verbose=True, random_state=42, cv=3)\n",
    "        clf.fit(train, y_train)\n",
    "        p = clf.best_params_\n",
    "        parameters.append(p)\n",
    "        d = tree.DecisionTreeClassifier(max_depth = p['max_depth'],\n",
    "                                      max_leaf_nodes = p['max_leaf_nodes'],\n",
    "                                      criterion = p['criterion'],\n",
    "                                      random_state = 42)\n",
    "        d2 = d.fit(train, y_train)\n",
    "        pred = d2.predict(test)\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        s = SSE(y_test, pred)\n",
    "        accuracy.append(acc)\n",
    "        sse.append(s)\n",
    "    data = {'Number of Features': n, 'Parameters': parameters, 'Accuracy': accuracy, 'SSE': sse}\n",
    "    dataframe = pd.DataFrame(data = data)\n",
    "    best = dataframe.loc[dataframe['Accuracy'].idxmax()]\n",
    "    best_k = best[0]\n",
    "    best_params = best[1]\n",
    "    return dataframe, best_k, best_params\n",
    "    \n",
    "parameters = {'max_depth':range(1,1000), 'criterion' :['gini', 'entropy'],\n",
    "              'max_leaf_nodes':range(1,1000)}\n",
    "\n",
    "white_tree_df, white_tree_best_k, white_tree_best_params = optimize_tree(white_x, white_train_x, white_train_y, white_test_x, white_test_y, parameters)   \n",
    "red_tree_df, red_tree_best_k, red_tree_best_params = optimize_tree(red_x, red_train_x, red_train_y, red_test_x, red_test_y, parameters)   \n",
    "\n",
    "white_tree_train_selected, white_tree_test_selected, white_tree_selected_features = FeatureSelection(white_tree_best_k, white_x, white_train_x, white_train_y, white_test_x, white_test_y)\n",
    "red_tree_train_selected, red_tree_test_selected, red_tree_selected_features = FeatureSelection(red_tree_best_k, red_x, red_train_x, red_train_y, red_test_x, red_test_y)\n",
    "\n",
    "white_tree_pred = do_tree(white_tree_train_selected, white_train_y, white_tree_test_selected, white_test_y, white_tree_best_params, 'White')\n",
    "red_tree_pred = do_tree(red_tree_train_selected, red_train_y, red_tree_test_selected, red_test_y, red_tree_best_params, 'Red')\n",
    "\n",
    "# best for white is 9 features, 827 leaf nodes, 672 max depth, and gini criterion\n",
    "# best for red is 2 features, 65 leaf nodes, 144 max depth, and gini criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "def gaussian_nb(x_train, y_train, x_test, y_test, color):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    y_pred = gnb.predict(x_test)\n",
    "    data_analyze(y_test, y_pred, color, \"GNB\")\n",
    "\n",
    "gaussian_nb(white_train_x, white_train_y, white_test_x, white_test_y,\"White\")\n",
    "gaussian_nb(red_train_x, red_train_y, red_test_x, red_test_y,\"Red\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-nearest neighbor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# feature selection\n",
    "# testing feature selection produced best results for using all features for both datasets   \n",
    "def do_knn(train_x, train_y, test_x, test_y, params, color):\n",
    "    k = KNeighborsClassifier(n_neighbors = params['n_neighbors'],\n",
    "                           weights = params['weights'])\n",
    "    k.fit(train_x, train_y)\n",
    "    pred = k.predict(test_x)\n",
    "    data_analyze(test_y, pred, color, 'KNN')\n",
    "    return pred\n",
    "\n",
    "def optimize_knn(df, x_train, y_train, x_test, y_test, params):\n",
    "    n = []\n",
    "    parameters = []\n",
    "    accuracy = []\n",
    "    sse = []\n",
    "    for i in range(1,12):\n",
    "        n.append(i)\n",
    "        train, test, x = FeatureSelection(i, df, x_train, y_train, x_test, y_test)\n",
    "        knn = KNeighborsClassifier()\n",
    "        clf = GridSearchCV(knn, params, scoring='accuracy', n_jobs=1, verbose=True, cv=3)\n",
    "        clf.fit(train, y_train)\n",
    "        p = clf.best_params_\n",
    "        parameters.append(p)\n",
    "        k = KNeighborsClassifier(n_neighbors = p['n_neighbors'],\n",
    "                           weights = p['weights'])\n",
    "        k.fit(train, y_train)\n",
    "        pred = k.predict(test)\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        s = SSE(y_test, pred)\n",
    "        accuracy.append(acc)\n",
    "        sse.append(s)\n",
    "    data = {'Number of Features': n, 'Parameters': parameters, 'Accuracy': accuracy, 'SSE': sse}\n",
    "    dataframe = pd.DataFrame(data = data)\n",
    "    best = dataframe.loc[dataframe['Accuracy'].idxmax()]\n",
    "    best_k = best[0]\n",
    "    best_params = best[1]\n",
    "    return dataframe, best_k, best_params\n",
    "\n",
    "parameters = {'n_neighbors':range(1,20), 'weights':['uniform', 'distance']}\n",
    "\n",
    "red_knn_df, red_knn_best_k, red_knn_best_params = optimize_knn(red_x, red_train_x, red_train_y, red_test_x, red_test_y, parameters)   \n",
    "white_knn_df, white_knn_best_k, white_knn_best_params = optimize_knn(white_x, white_train_x, white_train_y, white_test_x, white_test_y, parameters)  \n",
    "\n",
    "white_knn_train_selected, white_knn_test_selected, white_knn_selected_features = FeatureSelection(white_knn_best_k, white_x, white_train_x, white_train_y, white_test_x, white_test_y)\n",
    "red_knn_train_selected, red_knn_test_selected, red_knn_selected_features = FeatureSelection(red_knn_best_k, red_x, red_train_x, red_train_y, red_test_x, red_test_y)\n",
    "\n",
    "white_knn_pred = do_knn(white_knn_train_selected, white_train_y, white_knn_test_selected, white_test_y, white_knn_best_params, 'White')\n",
    "red_knn_pred = do_knn(red_knn_train_selected, red_train_y, red_knn_test_selected, red_test_y, red_knn_best_params,  'Red')\n",
    "\n",
    "# best for white is 11 features, 17 NN, weights = distance\n",
    "# best for red is 5 features, 13 NN, weights = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "def KNR(x_train, y_train, x_test, y_test, color=None):\n",
    "    grid_search = {\n",
    "        'weights': ['distance'],\n",
    "        'n_neighbors': range(1, 50),\n",
    "        'n_jobs': [1],\n",
    "        'algorithm': ['ball_tree']\n",
    "        }\n",
    "    best_w = {'algorithm': ['ball_tree'], 'n_jobs': [1], 'n_neighbors': [26], 'weights': ['distance']}\n",
    "    best_r = {'algorithm': ['ball_tree'], 'n_jobs': [1], 'n_neighbors': [2.5], 'weights': ['distance']}\n",
    "    param=None\n",
    "    if color == 'white':\n",
    "        param = best_w\n",
    "    elif color == 'red':\n",
    "        param = best_r\n",
    "    else:\n",
    "        param = grid_search\n",
    "    model = KNeighborsRegressor()\n",
    "    clf = GridSearchCV(model, grid_search, n_jobs=2, verbose=True, cv=5)  # cv=3 so that we have enough classes in each k-fold\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    y_pred = np.rint(y_pred)  # round predictions to nearest integer for classification\n",
    "\n",
    "    if color == 'white' or color == 'red':\n",
    "        print('best parameters: {}', clf.best_params_)\n",
    "        data_analyze(y_test, y_pred, color, \"RNC\")\n",
    "        # A = kneighbors_graph(x_test, 2, mode='connectivity', include_self=True)\n",
    "        # print(A)\n",
    "\n",
    "    if color==None:\n",
    "        print('best parameters: {}', clf.best_params_)\n",
    "        print('best score: {}', clf.best_score_)\n",
    "        print(\"MAE: {}\", mean_absolute_error(y_test, y_pred)) \n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(precision_score(y_test, y_pred, average=None, zero_division=0))\n",
    "    \n",
    "KNR(white_train_x, white_train_y, white_test_x, white_test_y, 'white')\n",
    "KNR(red_train_x, red_train_y, red_test_x, red_test_y, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machines\n",
    "from sklearn import svm\n",
    "def svm_function(x_train, y_train, x_test, y_test, color):\n",
    "    rbf = svm.SVC(kernel = 'rbf', random_state = 42)\n",
    "    rbf.fit(x_train,y_train)\n",
    "    y_pred = rbf.predict(x_test)\n",
    "    data_analyze(y_test, y_pred, color, \"SVM\")\n",
    "\n",
    "svm_function(white_train_x, white_train_y, white_test_x, white_test_y,\"White\")\n",
    "svm_function(red_train_x, red_train_y, red_test_x, red_test_y,\"Red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network - might not have great performance\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def MLP_Regressor(x_train, y_train, x_test, y_test, color=None):\n",
    "    grid_search = {\n",
    "        'activation': ['logistic', 'identity', 'tanh', 'relu'],\n",
    "        'alpha': [0.01, 0.001, 0.0001, 0.00001],\n",
    "        'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "        'solver': ['lbfgs', 'sgd', 'adam'], \n",
    "        'random_state':[42],\n",
    "        'max_iter': [500],\n",
    "        }\n",
    "    best_w = {'activation': ['relu'], 'alpha': [0.01], 'learning_rate': ['constant'], 'random_state': [42], 'solver': ['sgd'], 'max_iter': [100000]}\n",
    "    best_r = {'activation': ['tanh'], 'alpha': [0.01], 'learning_rate': ['constant'], 'random_state': [42], 'solver': ['adam'], 'max_iter': [100000]}\n",
    "    model = MLPRegressor()\n",
    "    param = None\n",
    "    if color == 'white': \n",
    "        param = best_w\n",
    "    elif color == 'red':\n",
    "        param = best_r\n",
    "    else:\n",
    "        param = grid_search\n",
    "    clf = GridSearchCV(model, param, n_jobs=1, verbose=True, cv=5)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    y_pred = np.rint(y_pred)  # round predictions to nearest integer for classification\n",
    "\n",
    "    if color == 'white' or color == 'red':\n",
    "        data_analyze(y_test, y_pred, color, \"MLP\")\n",
    "\n",
    "    if color==None:\n",
    "        print('best parameters: {}', clf.best_params_)\n",
    "        print('best score: {}', clf.best_score_)\n",
    "        print(\"MAE: {}\", mean_absolute_error(y_test, y_pred)) \n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(precision_score(y_test, y_pred, average=None, zero_division=0))\n",
    "\n",
    "MLP_Regressor(white_train_x, white_train_y, white_test_x, white_test_y, 'white')\n",
    "MLP_Regressor(red_train_x, red_train_y, red_test_x, red_test_y, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting performance\n",
    "# bar graphs to compare performance of classifiers\n",
    "\n",
    "plot_metrics(score_df, 'Accuracy', 'White')\n",
    "plot_metrics(score_df, 'Accuracy', 'Red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
